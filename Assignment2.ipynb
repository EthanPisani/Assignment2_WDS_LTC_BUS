{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: JSON to CSV Conversion and Data Visualization\n",
    "## Overview:\n",
    "\n",
    "In this assignment, you'll:\n",
    "\n",
    "Read a JSON file containing transportation data.\n",
    "Convert the data to a CSV file.\n",
    "Visualize the data using Matplotlib and Seaborn using the dataset output.\n",
    "\n",
    "Dataset:\n",
    "\n",
    "The dataset contains transportation information, including delay times, scheduled times, and route IDs. Each JSON file holds trip data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Install and import libraries, Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade tqdm\n",
    "!{sys.executable} -m pip install --upgrade requests\n",
    "!{sys.executable} -m pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "dataset_url = \"https://gitea.zuzu.red/EthanPisani/LTC-Bus/media/branch/main/sample_data/day_dataset.zip\"\n",
    "r = requests.get(dataset_url, allow_redirects=True)\n",
    "open('data/day_dataset.zip', 'wb').write(r.content)\n",
    "\n",
    "# unzip the dataset\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"data/day_dataset.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"data\")\n",
    "\n",
    "# remove the zip file\n",
    "import os\n",
    "os.remove(\"data/day_dataset.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "import tqdm\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Inspecting the data\n",
    "\n",
    "In this section we will inpect the data and see what it does. Try to play arround with the json file and get data into a test csv file.\n",
    "\n",
    "Data points such as: scheduled unix timestamp, route_id, delay, stop_id, vehicle_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "unixTime = 1730113021 # timestamp in unix time that the snapshot was taken (in the file name)\n",
    "# read the test file\n",
    "with open('data/TripUpdate1730113021.json', 'r') as f:\n",
    "    try:\n",
    "        data = json.load(f)\n",
    "    except ValueError:\n",
    "        print(\"File is empty\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    #print\n",
    "    # print(json.dumps(data, indent=4))\n",
    "    output_json = [] # list of dict data to save to a file\n",
    "    for entity in data.get(\"entity\", []): # loop through each entity (is a bus update object)\n",
    "        entity_id = entity.get(\"id\", None)\n",
    "        trip_update = entity.get(\"trip_update\", {}) # data in the update\n",
    "        vehicle_info = trip_update.get(\"vehicle\", {}) # vehicle info\n",
    "        trip = trip_update.get(\"trip\", {})\n",
    "        route_id = trip.get(\"route_id\", None)\n",
    "            \n",
    "\n",
    "        # test prints, play arround with the data to see what is available\n",
    "        print(\"Entity ID: \", json.dumps(entity_id, indent=4))\n",
    "        print(\"Trip Update: \", json.dumps(trip_update, indent=4))\n",
    "        print(\"Vehicle Info: \", json.dumps(vehicle_info, indent=4))\n",
    "        \n",
    "        # test output json\n",
    "        output_json.append({\n",
    "            \"entity_id\": entity_id,\n",
    "            \"route_id\": route_id,      \n",
    "        })\n",
    "\n",
    "   \n",
    "    # save output json to a csv file\n",
    "    with open('output_test.csv', 'w') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=output_json[0].keys())\n",
    "        writer.writeheader()\n",
    "        for row in output_json:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# You can open the output in a new file at the bottom of the jupyter notebook output cell\n",
    "# looks like this:\n",
    "# Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2: Reading and Converting JSON to CSV\n",
    "\n",
    "Read the JSON file. Use Python's json module to load data from a file.\n",
    "Transform the data. Extract relevant fields like route_id, stop_id, delay, and scheduled_time.\n",
    "Save to CSV. Use the csv module or Pandas to save the extracted data as a CSV file.\n",
    "\n",
    "## No need to edit this function!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process files in parallel\n",
    "def process_files(file_names):\n",
    "    extracted_data = []\n",
    "    seen_stops = set()\n",
    "    stop_id_map = {}\n",
    "\n",
    "    for file_name in tqdm.tqdm(file_names):\n",
    "        time_stamp = int(file_name.split(\"TripUpdate\")[1].split(\".json\")[0])\n",
    "\n",
    "        # Read and process the JSON file\n",
    "        with open(file_name, 'r') as file:\n",
    "            try:\n",
    "                data = json.load(file)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading file: {file_name}\")\n",
    "                continue\n",
    "\n",
    "            for entity in data.get(\"entity\", []):\n",
    "                entity_id = entity.get(\"id\", None)\n",
    "                trip_update = entity.get(\"trip_update\", {})\n",
    "                vehicle_info = trip_update.get(\"vehicle\", {})\n",
    "                vehicle_id = vehicle_info.get(\"id\", None) if vehicle_info else None\n",
    "\n",
    "                stop_time_updates = trip_update.get(\"stop_time_update\", [])\n",
    "                trip = trip_update.get(\"trip\", {})\n",
    "                route_id = trip.get(\"route_id\", \"\")\n",
    "\n",
    "                for stop in stop_time_updates:\n",
    "                    arrival_info = stop.get(\"arrival\", {})\n",
    "                    departure_info = stop.get(\"departure\", {})\n",
    "\n",
    "                    stop_id = stop.get(\"stop_id\", None)\n",
    "\n",
    "                    if arrival_info:\n",
    "                        delay = arrival_info.get(\"delay\", None)\n",
    "                        scheduled_time = arrival_info.get(\"schedule_time\", None)\n",
    "                        actual_time = arrival_info.get(\"time\", None)\n",
    "                    elif departure_info:\n",
    "                        delay = departure_info.get(\"delay\", None)\n",
    "                        scheduled_time = departure_info.get(\"schedule_time\", None)\n",
    "                        actual_time = departure_info.get(\"time\", None)\n",
    "                    else:\n",
    "                        delay = None\n",
    "                        scheduled_time = None\n",
    "                        actual_time = None\n",
    "\n",
    "                    if actual_time and time_stamp - 60 <= actual_time < time_stamp + 60:\n",
    "                        # Efficiently convert times\n",
    "                        ts = pd.to_datetime(scheduled_time, unit='s')\n",
    "                        scheduled_time_second = ts.hour * 3600 + ts.minute * 60 + ts.second\n",
    "                        ts2 = pd.to_datetime(actual_time, unit='s')\n",
    "                        actual_time_second = ts2.hour * 3600 + ts2.minute * 60 + ts2.second\n",
    "\n",
    "                        day_of_week = ts.weekday()\n",
    "                        day_of_year = ts.dayofyear\n",
    "                        if stop_id not in seen_stops:\n",
    "                            seen_stops.add(stop_id)\n",
    "                            stop_id_map[stop_id] = len(stop_id_map)\n",
    "\n",
    "                        extracted_data.append({\n",
    "                            \"route_id\": route_id,\n",
    "                            \"vehicle_id\": vehicle_id,\n",
    "                            \"stop_id\": stop_id_map[stop_id],\n",
    "                            \"delay\": delay,\n",
    "                            \"scheduled_time\": scheduled_time_second,\n",
    "                            \"actual_time\": actual_time_second,\n",
    "                            \"day\": day_of_week,\n",
    "                            \"day_of_year\": day_of_year\n",
    "                        })\n",
    "\n",
    "    return extracted_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Save data to CSV File\n",
    "\n",
    "Write a function to save the dict as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_csv(extracted_data, file_name):\n",
    "    # Save the extracted data to a CSV file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"data/day_dataset\"\n",
    "# Get all the files in the dataset folder\n",
    "files = glob.glob(f\"{dataset_folder}/*.json\")\n",
    "files.sort()\n",
    "\n",
    "extracted_data = []\n",
    "\n",
    "# this will take a while (5-20 minutes)\n",
    "extracted_data = process_files(files)\n",
    "# Save the extracted data to a CSV file\n",
    "save_data_to_csv(extracted_data, \"extracted_data.csv\")\n",
    "print(\"Data extraction complete!\")\n",
    "\n",
    "extracted_data = pd.read_csv(\"extracted_data.csv\")\n",
    "extracted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only route 9\n",
    "extracted_data_9 = extracted_data[extracted_data[\"route_id\"] == 9]\n",
    "print(extracted_data_9.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Visualization\n",
    "\n",
    "### Step 0: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# read data\n",
    "trip_dataset = pd.read_csv(\"extracted_data.csv\")\n",
    "\n",
    "# remove nans\n",
    "trip_dataset = trip_dataset.dropna()\n",
    "trip_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Analyze Delay Distribution for Each Route\n",
    "\n",
    "Create a visualization to analyze the distribution of delays for each route_id. \n",
    "Use a boxplot to summarize delays and observe variations between routes.\n",
    "\n",
    "Steps:\n",
    "\n",
    "- Use a Seaborn boxplot to plot delay on the y-axis and route_id on the x-axis.\n",
    "- Customize the plot with appropriate labels and a title for clarity.\n",
    "- Add gridlines or style to enhance readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the boxplot using route_id and delay\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Compare Scheduled vs Actual Times\n",
    "\n",
    "Create a scatter plot to compare scheduled_time and actual_time for all stops. Use different colors for each route_id to observe how routes differ in time deviations.\n",
    "\n",
    "Steps:\n",
    "\n",
    "-    Use Matplotlib's scatter function or Seaborn's scatterplot for the visualization.\n",
    "-    Use only one route from the dataset\n",
    "-    Create a new continuous numerical feature, \"hour\", that is the hour of the day with decmials. 2:30 AM would convert to 2.5 for example.\n",
    "-    Plot hour on the x-axis and delay on the y-axis with an Alpha value that looks good.\n",
    "-    Add labels and title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatter plot for route_id 10 delay over actual time, c\n",
    "trip_dataset_10 = \n",
    "# create new feature for hour of the day\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
